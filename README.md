# Introduction 
Data Engineering Project

This is a take home test for the front office engineering team.
You're required to fork this repository and return a link to your repository with the completed exercise.

# Restrictions.
1. You have ~48hrs to complete the take home test after you have been given the link to the repository.
2. You will be required to walk through the answers to the questions in the follow up interview.
3. You can use any programming language you like but we predominantly use python 3 in the front office engineering team. 

# Test Question
1. Write code to run a google search for 'how to data engineering'. We want to scrape the first 5 links in that google search and store the corresponding html.
2. Write a docker file that the above code will run including the commands to build the docker container and how to run it.

# How you will be assessed.
We are looking for a well engineered solution that is ready to ship (not a single script file).  Your code needs to demonstrate the following:
1. Your code will need to solve the problem.
2. Your code needs to be packaged and include your environment setup.
3. Your code needs to scale, Think about runtime, run environment and memory.
4. Your code needs to be clean and well tested.
5. Make sure you add a README and all required documentation.

## Questions in the interview (written answers are not required)
1. What are the libraries you have used and why?
2. Does your algorithm scale? What about if we wanted to store the first 50k responses?
3. How would you design a data pipeline to process the output from the scraped websites?
4. How would your design fit into an event driven architecture?
5. How would you architect the application, data pipeline in AWS or another cloud provider?
